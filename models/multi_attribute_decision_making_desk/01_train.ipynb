{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84939c3-dd95-4a82-b3f7-c659a2a882f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multi-attribute decision making\n",
    "\n",
    "Andrew Howes\n",
    "\n",
    "July 2022\n",
    "\n",
    "Multi-attribute decision making is the problem of choosing between multiple options each of which is described as a set of attribute/value pairs. People can be thought of as multi-attribute decision makers when for example they choose between different apartments, cars, or music channels. Payne, Bettman et al. conducted extensive studies of multi-attribute decision making in the 1980s and 1990s. \n",
    "\n",
    "For people, one part of the muti-attribute problem involves gathering information and more specifically, in what order to gather attribute/value pairs and when to stop. Typically, a person will not seek to gather information about all attribute/value pairs before stopping gathering information and making a decision. \n",
    "\n",
    "The process of information gathering is believed to be an active, sequential process with each decision as to what to do next informed by the information already gathered.\n",
    "\n",
    "Typically, people gather information from computer displays using eye-movements and fixations. The pattern of eye-movements is known to be influenced by the design of the interface but also by the relative value of the attributes to determining the utility of the outcome.\n",
    "\n",
    "The purpose of this notebook is to introduce a reinforcement learning model of how human's gather information in service of multi-attribute decisions. The notebook loosely follows the logic of Chen et al. (2017).\n",
    "\n",
    "Rather than strategies being programmed into the model, instead a policy for how to move the eyes is learned using reinforcement learning. The learned policy is the optimal solution to a problem that is defined by the constraints imposed by the oculomotor and perceptual systems and by the reward function. \n",
    "\n",
    "<img src=\"image/example_decision_task.png\" alt=\"An example decision task involving a choice between 3 apartments. Overlaid with an illustration of a typical pattern of eye-movements.\" width=\"500\" height=\"400\">\n",
    "\n",
    "The decision problem is illustrated in the above figure. Here there is a choice between three apartments, each of which has three attributes. The attribute values are represented in a table. The red circles represent a sequence of eye-movements used to gather relevant information. While these eye-movements are fictional they represent a typical pattern in which the user has gathered all information about rents before looking at only the Location of Apartment B and only the sizes of Apartments A and B. Moreover, the pattern suggests a decision strategy known as 'decision-by-aspects'; here, attribute values are compared rather than each option being assessed independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19539b13-a965-4f76-95ba-4589ef6db35c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The cognitive architecture\n",
    "\n",
    "The constraints of the model in this notebook are defined in a cognitive architecture -- an information processing model of the mind.\n",
    "\n",
    "<img src=\"image/architecture.png\" alt=\"Box diagram of a cognitive model.\" width=\"700\" height=\"400\">\n",
    "\n",
    "A cognitive architecture represents a commitment to a theory of how information is processed in the human mind. The cognitive architecture in the figure consists of five modules (inside the dashed box) that interact with an external world.\n",
    "\n",
    "Below, the modules have the following properties:\n",
    "\n",
    "* **World** On each trial, a \n",
    "* **Perception** The location of target location stimuli are corrupted by Gaussian noise in human vision. The standard deviation of noise increases linearly with eccentricity from the fovea. \n",
    "* **Memory** Sequences of stimuli are optimally integrated.\n",
    "* **Utility** Rewards are received for getting closer to the target.\n",
    "* **Motor** Intended eye movements (oculomotor actions) are corrupted by signal dependent Gaussian noise to generate responses.\n",
    "* **Control**  The Control module observes the memory and receives a reward. It learns a policy for making eye movements to the target that maximises the reward.\n",
    "\n",
    "A python implementation of each module is described below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cebf7d7-774c-4374-ba2f-a8679e7220de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import and configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oeJU5wJR7A8V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1652,
     "status": "ok",
     "timestamp": 1643210006123,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "oeJU5wJR7A8V",
    "outputId": "f8e53d98-820c-4a31-b9f5-e4b5c46bd72b"
   },
   "outputs": [],
   "source": [
    "# This cell only for users of Google Colab.\n",
    "# No need to run this if you are using Jupyter notebooks\n",
    "# Mount Google drive and change directory into the project folder\n",
    "# Only needs to be run once\n",
    "\n",
    "#!pip install stable_baselines3\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#%cd '/content/drive/MyDrive/CHI22CMT/CHI22_CogMod_Tutorial/03-Reinforcement-Learning/034_Gaze_based_Interaction'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "P44tljjb8hBC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6305,
     "status": "ok",
     "timestamp": 1643209694066,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "P44tljjb8hBC",
    "outputId": "d635fb70-1df0-4ab3-f15e-13b3d7b2fdc9"
   },
   "outputs": [],
   "source": [
    "# Load local modules\n",
    "# gazetools is a module that contains functions for modeling gaze-based interaction.\n",
    "\n",
    "from tools import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd229b7d-169a-45fa-b327-de4eb2db96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder for the output files\n",
    "\n",
    "#output_dir = 'output/'\n",
    "\n",
    "#if not os.path.exists(output_dir):\n",
    "#    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100b0d0e-33c1-4d21-b7e1-d320a62f54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".folder_number_for_results.pickle\n"
     ]
    }
   ],
   "source": [
    "fldr = create_new_folder('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6554f211-129f-499d-942a-8ba18735be9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-missile",
   "metadata": {
    "id": "boolean-missile",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### World Module\n",
    "\n",
    "The World generates a **stimulus** and the agent can **respond** with an eye-movement.\n",
    "\n",
    "The **stimulus** is the currently foveated cell of a table of values that are organised according to the figure above with options on rows and attributes in columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bacterial-archives",
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1643209742334,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "bacterial-archives"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.51627866 -3.0033507   0.70051273]\n",
      " [-0.02074139  1.28139589 -1.37161614]\n",
      " [-0.23353773 -1.10631136 -1.45249904]\n",
      " [ 0.          0.          0.        ]]\n",
      "{'fixation': [3, 1], 'values': array([[ 0.        , -3.0033507 ,  0.        ],\n",
      "       [ 0.        ,  1.28139589,  0.        ],\n",
      "       [ 0.        , -1.10631136,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]])}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "class MultiAttributeDecisionMaking():\n",
    "    ''' There is a table of attribute values and a set of decision buttons by which an option can be chosen. \n",
    "        There is a fixation on one of the values or on a decision button.\n",
    "        '''\n",
    "    \n",
    "    def __init__(self, theta, output_dir):\n",
    "        self.theta=theta\n",
    "        self.output_dir=output_dir\n",
    "        \n",
    "    def reset(self):\n",
    "        ''' The state of the World consists of a table of attribute/value pairs.'''\n",
    "        \n",
    "        def get_display():\n",
    "            ''' A display consists of options on rows and attributes in columns. \n",
    "                The last column is the option buttons, so do not assign values.\n",
    "            '''\n",
    "            n_cols = self.theta['n_attr']+1\n",
    "            self.display_dims = (n_cols, self.theta['n_options'])\n",
    "            self.display = np.zeros(self.display_dims)\n",
    "            # generate a table of values.\n",
    "            # would be better to first generate stds and map onto (-1,1) rather than clip.\n",
    "            value_dims = (self.theta['n_attr'], self.theta['n_options'])\n",
    "            values = np.random.normal(0, 1, value_dims)\n",
    "            self.values = np.clip(values, -0.9, 1) # reserve -1 for a null value meaning that the cell has not yet been looked at.\n",
    "            self.display[0:-1,] = values\n",
    "            return np.array( self.display )\n",
    "    \n",
    "        # the initial fixation\n",
    "        self.fixation = np.array([-1,-1])\n",
    "        # the target location for this episode\n",
    "        self.display = get_display()\n",
    "        return self.display\n",
    "    \n",
    "    def get_background(self, eps):\n",
    "        ''' Generate a list of dictionaries each of which describes an element in the World.\n",
    "        '''\n",
    "        bgrnd = []\n",
    "        for x in range(0,self.values.shape[0]):\n",
    "            for y in range(0,self.values.shape[1]):\n",
    "                bgrnd.append( {'type':'value', 'value':round(self.values[x,y]*100), 'x':x, 'y':y, 'episode':eps} )\n",
    "        bgrnd.append( {'type':'button', 'value':'Option A', 'x':3, 'y':0, 'episode':eps} )\n",
    "        bgrnd.append( {'type':'button', 'value':'Option B', 'x':3, 'y':1, 'episode':eps} )\n",
    "        bgrnd.append( {'type':'button', 'value':'Option C', 'x':3, 'y':2, 'episode':eps} )\n",
    "        return bgrnd\n",
    "\n",
    "    def step(self, response):\n",
    "        ''' The response is a discrete x,y display coordinate. \n",
    "            If the fixation is on a value then return its value in the display[] array as the (partial) observation.\n",
    "            If the fixation is a button then return all attr values -- this gives ground truth feedback to the agent.\n",
    "        '''\n",
    "        self.fixation = response\n",
    "        s_values = np.zeros(self.display_dims)\n",
    "        # if an option has been selected then done=True...\n",
    "        if response[0]==self.theta['n_attr']:\n",
    "            done = True\n",
    "            # experience and perceive all attribute values of the selected option.\n",
    "            s_values[:,response[1]] = self.display[:,response[1]] \n",
    "            stimulus = {'fixation': self.fixation, 'values':s_values }\n",
    "        else:\n",
    "            # just perceive the fixated item...\n",
    "            done = False\n",
    "            # only perceive the foviated value\n",
    "            s_values[ response[0], response[1] ] = self.display[ response[0], response[1] ]\n",
    "            stimulus = {'fixation': self.fixation, 'values':s_values }\n",
    "        return stimulus, done\n",
    "\n",
    "class World(MultiAttributeDecisionMaking):\n",
    "    pass\n",
    "\n",
    "theta = {'n_attr':3, 'n_options':3}\n",
    "world = World(theta, fldr)\n",
    "display = world.reset()\n",
    "print( display )\n",
    "stimulus, done = world.step([3,1])\n",
    "print( stimulus )\n",
    "print (done)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ead0e8-481f-4af5-8351-433684c306da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Perception Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9b29d5-2ab8-4f65-9bab-802d60507b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Vision():\n",
    "    ''' Foveated vision but with out any peripheral vision.\n",
    "    '''\n",
    "    def __init__(self, theta):\n",
    "        self.theta = theta\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def step(self, stimulus):\n",
    " \n",
    "        percept = stimulus\n",
    "        return stimulus\n",
    "\n",
    "class Perception(Vision):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31c382-0988-4cd9-bf9c-8f629cd8b07a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Memory Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a7f30f-167d-4080-bcfe-de9db2129635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.49360801  0.1914226  -0.20784184]\n",
      " [ 0.48980696 -0.24177364  0.38893511]\n",
      " [-0.69608156  2.1177223   1.0494112 ]\n",
      " [ 0.          0.          0.        ]]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[-1.         -1.         -1.         -1.         -0.24177364 -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  0.          0.          0.          0.          1.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "class Memory():\n",
    "    ''' Keep a memory of percepts and fixations. Compute an observation of memory. \n",
    "        The memory is spatially structured.\n",
    "        self.valmem is the memory of perceived values.\n",
    "        self.fixmem is the memory of perceived fixation locations.\n",
    "        These are concatenated to form the observation.\n",
    "        An alternative to fixmem is a memory of variances combined with a Kalman filter.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, theta):\n",
    "        self.theta = theta\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.memory_dims = (self.theta['n_attr']+1, self.theta['n_options'])\n",
    "        self.valmem = np.full(self.memory_dims, -1, dtype=float)\n",
    "        self.fixmem = np.zeros(self.memory_dims)\n",
    "        observation = np.concatenate((self.valmem.flatten(), self.fixmem.flatten()))\n",
    "        return observation\n",
    "    \n",
    "    def step(self, percept):\n",
    "        self.valmem[tuple(percept['fixation'])] = percept['values'][tuple(percept['fixation'])]\n",
    "        self.fixmem[tuple(percept['fixation'])] = 1\n",
    "        observation = np.concatenate((self.valmem.flatten(), self.fixmem.flatten()))\n",
    "        return observation\n",
    "\n",
    "display = world.reset()\n",
    "print(display)\n",
    "mem = Memory(theta)\n",
    "m = mem.reset()\n",
    "print(m)\n",
    "m = mem.step({'fixation': [1,1], 'values': display })\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed508a-784e-4ef5-9333-4c52a39fb0a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Utility Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d516283-c998-4af5-8757-b07836053f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fixation': [3, 0], 'values': array([[ 0.49503142, -0.18910854, -0.29926618],\n",
      "       [-0.17452262,  2.33538853, -0.3297507 ],\n",
      "       [ 0.79798782, -0.42632954,  1.28618541],\n",
      "       [ 0.        ,  0.        ,  0.        ]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "785.4858754442105"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Utility():\n",
    "    ''' Compute the reward given an observation.\n",
    "        Until a choice is made by focusing on the last column the reward is just the step cost.\n",
    "        Once a button in the last column has been foveated and a choice made then the reward is the weighted sum of the attribute values.\n",
    "        Note that all attribute values for the chosen option are in the percept... representing post choice experience.\n",
    "        (This may be corrupted by noise but is not in this version.)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, theta):\n",
    "        self.theta = theta\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def step(self, percept):\n",
    "        fixation = percept['fixation']\n",
    "        values = percept['values']\n",
    "        if fixation[0]==self.theta['n_attr']:\n",
    "            reward_values = values[0:3,fixation[1]]\n",
    "            reward_values = reward_values * self.theta['weights']\n",
    "            reward = reward_values.sum(axis=0)\n",
    "        else:\n",
    "            reward = -self.theta['step_cost']\n",
    "        return reward\n",
    "\n",
    "theta = {'n_attr':3, 'n_options':3, 'step_cost':1, 'weights':np.array([10,100,1000])}\n",
    "utility = Utility(theta)\n",
    "values = world.reset()\n",
    "percept = {'fixation': [3,0], 'values': values}\n",
    "print(percept)\n",
    "utility.step(percept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44745453-faf5-4b53-bf4d-ad80b8f19c79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Motor Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aea2b1b-0778-46b1-9448-d21240c5dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Oculomotor():\n",
    "    \n",
    "    def __init__(self, theta):\n",
    "        ''' The current fixation is part of the motor system state. '''\n",
    "        self.theta = theta\n",
    "        self.fixation = np.array([-1,-1])\n",
    "    \n",
    "    def reset(self):\n",
    "        self.fixation = np.array([-1,-1])\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.fixation = action\n",
    "        return action\n",
    "\n",
    "class Motor(Oculomotor):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-alliance",
   "metadata": {
    "id": "combined-alliance",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Control Module\n",
    "\n",
    "The control module uses RL to find an optimal policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "157df96a-cad2-4fbb-9f2c-eda56738044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Control():\n",
    "    \n",
    "    def __init__(self, theta, env, output_dir):\n",
    "        self.env = env\n",
    "        self.theta = theta\n",
    "        self.output_dir = output_dir\n",
    "        self.policy_file = 'policy'\n",
    "        \n",
    "    def train(self, timesteps):\n",
    "        ''' Train the control module to find the optimal policy for the Gym environment.\n",
    "            Monitor() and PPO() are part of the stable_baselines3 package.\n",
    "            PPO (Proximal Policy Optimisation) is a class of RL algorithm https://openai.com/blog/openai-baselines-ppo/\n",
    "            '''\n",
    "        self.env = Monitor(self.env, self.output_dir)\n",
    "        self.policy = PPO('MlpPolicy', self.env, verbose=0, clip_range=0.15)\n",
    "        self.policy.learn(total_timesteps=int(timesteps))\n",
    "        self.policy.save(f'{self.output_dir}{self.policy_file}')\n",
    "        print('Done training.')\n",
    "       \n",
    "    def load_policy(self):\n",
    "        self.policy = PPO.load(f'{self.output_dir}/{self.policy_file}')\n",
    "        return self.policy\n",
    "\n",
    "    def run(self, n_episodes, filename):\n",
    "        '''\n",
    "        run the model for n_episodes and save its behaviour in a csv file.\n",
    "        Note that 'env' is a term used by Gym to describe everything but the controller.\n",
    "        '''\n",
    "        max_episodes = 900000\n",
    "        #if n_episodes > max_episodes:\n",
    "        #    print(f'We ask that you limit training to a max of {max_episodes} on the School of Computer Science AWS account.')\n",
    "        #    print(f'If you want to run more training episodes then please do so on a local computer.')\n",
    "        #    return\n",
    "\n",
    "        result = []\n",
    "        background = []\n",
    "        # repeat for n episodes\n",
    "        eps = 0\n",
    "        while eps < n_episodes:                \n",
    "            done = False\n",
    "            step = 0\n",
    "            obs = self.env.reset()\n",
    "            new_bgrnd = self.env.world.get_background(eps)\n",
    "            background = background + new_bgrnd\n",
    "            # record the initial state\n",
    "            init_action = (-1,-1)\n",
    "            info = self.env.get_info(init_action, obs, 0, False)\n",
    "            info['episode'] = eps\n",
    "            result.append(info)\n",
    "            # repeat until the gaze is on the target.\n",
    "            while not done:\n",
    "                step+=1\n",
    "                # get the next prediction action from the policy\n",
    "                action, _ = self.policy.predict(obs,deterministic = True)\n",
    "                obs, reward, done, info = self.env.step(action)\n",
    "                info['episode'] = eps\n",
    "                result.append( info )\n",
    "            eps+=1\n",
    "        #path = f'{self.output_dir}/{filename}'\n",
    "        #df = pd.DataFrame(result)\n",
    "        #df.to_csv(path,index=False)\n",
    "        data_to_csv( result, self.output_dir, filename )\n",
    "        data_to_csv( background, self.output_dir, 'display.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957556de-856e-4399-9cf5-b7d12f7db751",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## The Model\n",
    "\n",
    "The model is our model of cognition and the world. It is the environment for the control module. It defines the information flow between the modules defined above. \n",
    "\n",
    "It is defined as a Gym environment. For further information see: https://gym.openai.com/. gym.Env is a class provided by this library. The environments step function receives the action the controller and returns an observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6014653-7d44-4cc7-bbc3-cc53df9ec9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CogEnv(gym.Env):\n",
    "    ''' The CogEnv defines the environment for the controller.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, output_dir, theta={}, max_steps=10):\n",
    "\n",
    "        self.theta = theta\n",
    "        \n",
    "        self.motor = Motor(theta)\n",
    "        self.world = World(theta, output_dir)\n",
    "        self.perception = Perception(theta)\n",
    "        self.utility = Utility(theta)\n",
    "        self.memory = Memory(theta)\n",
    "        # The CogEnv defines the environment for the controller and therefore a Control object is not defined here.\n",
    "        \n",
    "        # The action_space and observation_space are required by gym. These define the range of each variable.\n",
    "        # Each action has an x,y coordinate.\n",
    "        # Each obsevation is of the entire display.\n",
    "        \n",
    "        self.n_actions = (self.theta['n_attr']+1, self.theta['n_options'])\n",
    "        self.action_space = spaces.Discrete(np.prod(self.n_actions))\n",
    "    \n",
    "        self.observation_space = default_box(24)\n",
    "        \n",
    "        # max_fixations per episode. Used to curtail exploration early in training.\n",
    "        self.max_steps = max_steps\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        self.motor.reset()\n",
    "        self.world.reset()\n",
    "        self.perception.reset()\n",
    "        self.utility.reset()\n",
    "        observation = self.memory.reset()\n",
    "\n",
    "        self.n_step = 0\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def step(self, action):\n",
    "        action = to_xy_coord( action, self.n_actions )\n",
    "        ''' Define the information flow between the modules. '''\n",
    "        response = self.motor.step(action)\n",
    "        stimulus, done = self.world.step(response)\n",
    "        percept = self.perception.step(stimulus)\n",
    "        observation = self.memory.step(percept)\n",
    "        reward = self.utility.step(percept)\n",
    "        \n",
    "        self.n_step+=1\n",
    "        # give up if been looking for too long\n",
    "        if self.n_step > self.max_steps:\n",
    "            done = True\n",
    "            reward = -3\n",
    "            \n",
    "        info = self.get_info( action, observation, reward, done )\n",
    "        \n",
    "        return observation, reward, done, info\n",
    "\n",
    "    def get_info(self, action, observation, reward, done ):\n",
    "        return {'step': self.n_step,\n",
    "                'fixation_x': action[0],\n",
    "                'fixation_y': action[1],\n",
    "                'observation': observation,\n",
    "                'reward': reward,\n",
    "                'done': done}\n",
    "\n",
    "def to_xy_coord( n, dims ):\n",
    "    mapping = tuple(np.ndindex(dims))\n",
    "    return mapping[n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daaacb8-115a-4e8c-a316-a189cdbadae5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520d53ed-a160-47ff-9432-3339f07c36ca",
   "metadata": {},
   "source": [
    "Define the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b0260eb-313c-4082-b92e-6a21cd2120eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta = {'n_attr':3, 'n_options':3, 'step_cost':0.01, 'weights':np.array([1,2,3])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6866d-fd75-43ee-b359-fef3a1870317",
   "metadata": {
    "id": "complex-covering",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34811351-d24c-4dd8-8269-ab2a31fae489",
   "metadata": {},
   "source": [
    "Step through the untrained model to check for simple bugs. Output a DataFrame with a row for each step.\n",
    "More comprehensive tests needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b388998-7cfe-4429-bdcf-3e08d4934adf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1643209756680,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "4ed00048",
    "outputId": "95f13fd2-30ad-43d9-8cab-1d127f6359d6"
   },
   "outputs": [],
   "source": [
    "model = CogEnv( fldr, theta=theta, max_steps=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14233301-7670-4195-a5ea-cbc471bed632",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1643209756680,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "4ed00048",
    "outputId": "95f13fd2-30ad-43d9-8cab-1d127f6359d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>fixation_x</th>\n",
       "      <th>fixation_y</th>\n",
       "      <th>observation</th>\n",
       "      <th>reward</th>\n",
       "      <th>done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.0, -1.0, 0.3823863722251043, -1.0, -1.0, -...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.0, -1.0, 0.3823863722251043, -0.6234380626...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.0, -1.0, 0.3823863722251043, -0.6234380626...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.0, -1.0, 0.3823863722251043, -0.6234380626...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[-1.0, -1.0, 0.3823863722251043, -0.6234380626...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.7994017625808375, -1.0, 0.3823863722251043...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.7994017625808375, -1.0, 0.3823863722251043...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.7994017625808375, -1.0, 0.3823863722251043...</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.7994017625808375, -1.0, 0.3823863722251043...</td>\n",
       "      <td>-1.576807</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  fixation_x  fixation_y  \\\n",
       "0     1           0           2   \n",
       "1     2           1           0   \n",
       "2     3           1           2   \n",
       "3     4           2           2   \n",
       "4     5           2           2   \n",
       "5     6           0           0   \n",
       "6     7           1           1   \n",
       "7     8           2           2   \n",
       "8     9           3           0   \n",
       "\n",
       "                                         observation    reward   done  \n",
       "0  [-1.0, -1.0, 0.3823863722251043, -1.0, -1.0, -... -0.010000  False  \n",
       "1  [-1.0, -1.0, 0.3823863722251043, -0.6234380626... -0.010000  False  \n",
       "2  [-1.0, -1.0, 0.3823863722251043, -0.6234380626... -0.010000  False  \n",
       "3  [-1.0, -1.0, 0.3823863722251043, -0.6234380626... -0.010000  False  \n",
       "4  [-1.0, -1.0, 0.3823863722251043, -0.6234380626... -0.010000  False  \n",
       "5  [-0.7994017625808375, -1.0, 0.3823863722251043... -0.010000  False  \n",
       "6  [-0.7994017625808375, -1.0, 0.3823863722251043... -0.010000  False  \n",
       "7  [-0.7994017625808375, -1.0, 0.3823863722251043... -0.010000  False  \n",
       "8  [-0.7994017625808375, -1.0, 0.3823863722251043... -1.576807   True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def step_test():\n",
    "    j=0\n",
    "    result = []\n",
    "    done = False\n",
    "    model.reset()\n",
    "    while not done:\n",
    "        # make a step with a randomly sampled action\n",
    "        obs, reward, done, info = model.step(model.action_space.sample())\n",
    "        result.append(info)\n",
    "        j+=1\n",
    "    df = pd.DataFrame(result)\n",
    "    return df, j\n",
    "\n",
    "info, i = step_test()\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a8d46-a29c-4aad-9b5d-026924ef86c3",
   "metadata": {},
   "source": [
    "Calculate the average number of steps taken by the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a8a530d-b199-434f-8d41-7f047cf81302",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1643209756680,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "4ed00048",
    "outputId": "95f13fd2-30ad-43d9-8cab-1d127f6359d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4\n"
     ]
    }
   ],
   "source": [
    "def mean_steps_taken():\n",
    "    rs = []\n",
    "    for k in range(0,10):\n",
    "        info, i = step_test()\n",
    "        rs.append(i)\n",
    "    return sum(rs) / len(rs)\n",
    "\n",
    "model.max_steps = 1000\n",
    "\n",
    "r = mean_steps_taken()\n",
    "        \n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-stevens",
   "metadata": {
    "id": "cognitive-stevens",
    "tags": []
   },
   "source": [
    "## Train the control module\n",
    "\n",
    "We can train the control module to generate a policy.\n",
    "\n",
    "By plotting the learning curve we can see whether the performance improves with training and whether the model approaches an optimum performance. We are interested in approximately optimal performance, so if the training curve is not approaching asymptote then we need to train with more timesteps or revise the model.\n",
    "\n",
    "We can see that at first the model uses hundreds of fixations to find the target, this is because it has not yet learned to move the gaze in a way that is informed by the observation. As it learns to do this, it takes fewer steps to gaze at the target and its performance improves.\n",
    "\n",
    "If our problem definition is correct then the model will get more 'human-like' the more that it is trained. In other words, training makes it a better model of interaction.\n",
    "\n",
    "If we assume that people are computationally rational then the optimal solution to the gaze problem (as defined above) predicts human behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "067f28d0-80f0-4c99-bc5d-57820c594c1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 66705,
     "status": "ok",
     "timestamp": 1643209827031,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "7d0910ac",
    "outputId": "d927873a-e745-4931-d6b8-fb6f3a668245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "model.max_steps = 12\n",
    "\n",
    "control = Control(theta, model, fldr)\n",
    "\n",
    "timesteps = 500000\n",
    "\n",
    "control.train(timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "871adbd9-8497-479a-badb-29c1c3fb6073",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 66705,
     "status": "ok",
     "timestamp": 1643209827031,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "7d0910ac",
    "outputId": "d927873a-e745-4931-d6b8-fb6f3a668245"
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_model(model,results_folder):\n",
    "    with open(f'{results_folder}/model.pickle', 'wb') as handle:\n",
    "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "save_model(model, fldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10dec29b-114c-4b20-9355-62a5a151f6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(fldr,800)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2797581-e41d-4859-9c7c-aaafa98dd00f",
   "metadata": {},
   "source": [
    "You should see a 'learning curve' in which as the model is trained with more 'timesteps' its performance improves. With more timesteps the rewards of each episode increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-georgia",
   "metadata": {
    "id": "japanese-georgia",
    "tags": []
   },
   "source": [
    "### Run the model\n",
    "Run the trained model and save a trace of each episode to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "after-evans",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 162308,
     "status": "ok",
     "timestamp": 1643210003598,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "after-evans",
    "outputId": "838f8f2b-9414-454a-8700-acfd39062bb8"
   },
   "outputs": [],
   "source": [
    "control.run( 1000, 'behaviour_trace.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bdefc5-7dfb-481e-a887-729c7a08be18",
   "metadata": {},
   "source": [
    "###Excercise\n",
    "\n",
    "Retrain the control module but with timesteps=300000. Inspect the learning curve and note that there is now a clear asymptote in performance which approaches 0 loss.\n",
    "\n",
    "Rerun the model to generate a new behaviour_trace.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-capture",
   "metadata": {
    "id": "stable-capture",
    "tags": []
   },
   "source": [
    "## Next\n",
    "\n",
    "Congratulations, you have now completed a Python notebook that introduces you to how to model cognition with RL. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-headquarters",
   "metadata": {
    "id": "weekly-headquarters"
   },
   "source": [
    "## References\n",
    "Chen, X., Starke, S. D., Baber, C., & Howes, A. (2017, May). A cognitive model of how people make decisions through interaction with visual displays. In Proceedings of the 2017 CHI conference on human factors in computing systems (pp. 1205-1216)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gaze-based-interaction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
